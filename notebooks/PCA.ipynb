{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PCA.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"eY0tpEgRxl4r","colab_type":"text"},"source":["# PCA Implementation\n","\n","Implements a PCA method that we will test on a small sample of the dataset."]},{"cell_type":"markdown","metadata":{"id":"UXnpOzjox9tu","colab_type":"text"},"source":["# 1 Set up Spark Environment\n","\n","Set up Spark environment so we can partition the data.\n","\n","References: \n","* https://towardsdatascience.com/pyspark-in-google-colab-6821c2faf41c"]},{"cell_type":"code","metadata":{"id":"IGPiqvb3yERq","colab_type":"code","colab":{}},"source":["# Install necessary dependencies, if needed (only need to run once!!!)\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","!wget -q http://www.gtlib.gatech.edu/pub/apache/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n","!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n","!pip install -q findspark"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P3kRznNJXIRh","colab_type":"code","outputId":"cd900342-1984-4acc-d8a4-ae96e0ff49af","executionInfo":{"status":"ok","timestamp":1587164327059,"user_tz":240,"elapsed":1445,"user":{"displayName":"Amy Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqLqJZ7tmS-RYlbHWq4vE0jqMMMMq8y5ez6PA-=s64","userId":"12521918565421128829"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# checks if it was installed properly (if so, you should see file spark-2.4.5-bin-hadoop2.7)\n","!ls"],"execution_count":0,"outputs":[{"output_type":"stream","text":["sample_data  spark-2.4.5-bin-hadoop2.7\tspark-2.4.5-bin-hadoop2.7.tgz\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"McqywJGKyH-4","colab_type":"code","colab":{}},"source":["# Set up environment path so we can run Pyspark in Colab\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GaBF_vOryTkJ","colab_type":"code","colab":{}},"source":["# Create local spark session\n","import findspark\n","findspark.init()\n","import pyspark\n","from pyspark.sql import SQLContext\n","sc = pyspark.SparkContext(appName=\"pca\")\n","sqlContext = SQLContext(sc)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fK9QSNNHxtgt","colab_type":"text"},"source":["## 2 TODO Load Raw Data\n","\n","See `data_loading.ipynb` for starter code.\n","\n","The full data is hosted on GCS. We only want a small sample of it, e.g. `val_data.tar` (~2 GB).\n","\n","References:\n","* https://stackoverflow.com/questions/51715268/how-to-import-data-from-google-cloud-storage-to-google-colab"]},{"cell_type":"code","metadata":{"id":"8Qiz3vKsx3kM","colab_type":"code","outputId":"b83aca30-fc07-478f-ef44-3b231a289448","executionInfo":{"status":"error","timestamp":1587164791601,"user_tz":240,"elapsed":491,"user":{"displayName":"Amy Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqLqJZ7tmS-RYlbHWq4vE0jqMMMMq8y5ez6PA-=s64","userId":"12521918565421128829"}},"colab":{"base_uri":"https://localhost:8080/","height":365}},"source":["from google.cloud import storage\n","import tarfile\n","\n","# Connect to GCS bucket\n","bucket_name = \"dataproc-staging-us-central1-759291875656-wohgf1sk\"\n","storage_client = storage.Client()\n","bucket = storage_client.bucket(bucket_name)\n","\n","# Identifying blobs of data in the bucket\n","file_prefix = \"data/\"\n","blobs = bucket.list_blobs(prefix=file_prefix, delimiter = '/')\n","\n","# Downloading a specific blob of data\n","file_name = \"val_data.tar\"\n","blob = bucket.get_blob(file_prefix + file_name)\n","blob.download_to_filename(\"val_data.tar\")\n","\n","# reading the data\n","tar_file = tarfile.open(\"val_data.tar\")\n","arr = []\n","for member in tar_file.getmembers():\n","    f = tar_file.extractfile(member)\n","    img_bytes = np.frombuffer(f, dtype=int)\n","    arr.append(img_bytes)\n","tar_file.close()"],"execution_count":0,"outputs":[{"output_type":"error","ename":"DefaultCredentialsError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mDefaultCredentialsError\u001b[0m                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-5943214b7ee5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Connect to GCS bucket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbucket_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"dataproc-staging-us-central1-759291875656-wohgf1sk\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mstorage_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mbucket\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbucket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/cloud/storage/client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, project, credentials, _http, client_info)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mproject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         super(Client, self).__init__(\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_http\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_http\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         )\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mno_project\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/cloud/client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, project, credentials, _http)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_http\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0m_ClientProjectMixin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0mClient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_http\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_http\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/cloud/client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, project)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mproject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_determine_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mproject\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             raise EnvironmentError(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/cloud/client.py\u001b[0m in \u001b[0;36m_determine_default\u001b[0;34m(project)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_determine_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;34m\"\"\"Helper:  use default project detection.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_determine_default_project\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/cloud/_helpers.py\u001b[0m in \u001b[0;36m_determine_default_project\u001b[0;34m(project)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \"\"\"\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mproject\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/auth/_default.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(scopes, request)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meffective_project_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDefaultCredentialsError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_HELP_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mDefaultCredentialsError\u001b[0m: Could not automatically determine credentials. Please set GOOGLE_APPLICATION_CREDENTIALS or explicitly create credentials and re-run the application. For more information, please see https://cloud.google.com/docs/authentication/getting-started"]}]},{"cell_type":"code","metadata":{"id":"2z6Gak1IYwXn","colab_type":"code","colab":{}},"source":["# display sample image\n","\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import io\n","\n","img_data = arr[0]\n","image = Image.open(io.BytesIO(img_data))\n","plt.imshow(image)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m-hDFW-oU6Yd","colab_type":"text"},"source":["## 3 Parallelize Data\n","\n","Parallelize the data so we can distribute work across the cluster."]},{"cell_type":"code","metadata":{"id":"jh7osem3a0z5","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KnDJqyYZVoxD","colab_type":"code","colab":{}},"source":["par_data = sc.parallelize(val_data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RZS3jDJcZxMB","colab_type":"code","colab":{}},"source":["# Test\n","print('Size:', par_data.count())\n","print('Sample Entry:', par_data.take(1))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"slhWZRjyYQGC","colab_type":"text"},"source":["## 4 Compute Covariance Matrix\n","\n","Function to compute the covariance of the data in an RDD."]},{"cell_type":"code","metadata":{"id":"5exiLhX2YVpV","colab_type":"code","colab":{}},"source":["def compute_covariance(data):\n","  \"\"\"\n","  Compute covariance matrix for given RDD.\n","  Args:\n","    data: (RDD of np arrays) RDD representing the data\n","  Returns:\n","    covmat: (np array) covariance matrix of the RDD\n","  \"\"\"\n","  n = data.count()\n","  mean = data.mean()\n","  data_0_mean = data.map(lambda m: m - mean)\n","  covmat = (data_0_mean\n","                .map(lambda mat: np.outer(mat.T, mat))\n","                .reduce(lambda x,y: x+y)) / float(n)\n","  return covmat"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iPN2o42nZNQK","colab_type":"text"},"source":["## 5 Eigendecomposition\n","\n","Perform eigendecomposition of covariance matrix to determine the directions of maximal variance, i.e. the principal components."]},{"cell_type":"code","metadata":{"id":"APUOts0nZZWo","colab_type":"code","colab":{}},"source":["from numpy.linalg import eigh\n","\n","def pca(data, k=2):\n","  \"\"\"\n","  Computes the top `k` principal components, their corresponding PCA scores, and eigenvalues.\n","  Args:\n","    data: (RDD of np arrays) RDD representing the data.\n","    k: (int) number of principal components to find\n","  Returns:\n","    (eigenvectors, scores, eigenvalues): (np.ndarray, RDD of np.ndarray, np.ndarray)\n","  \"\"\"\n","\n","  # Compute covariance matrix\n","  covmat = compute_covariance(data)\n","\n","  # Compute eigenvalues & eigenvectors\n","  eig_vals, eig_vecs = eigh(covmat)\n","\n","  # Sort the eigenvectors based on their eigenvalues\n","  inds = np.argsort(eig_vals)\n","  inds = inds[::-1]\n","\n","  # Find the `k` principal components, `k` scores, and all eigenvalues\n","  components = eig_vecs[:,inds[:k]]\n","  eigenvalues = eig_vals[inds]\n","  scores = data.map(lambda m: m.dot(components))\n","  \n","  return (components, scores, eigenvalues)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"36ZDQ1g7bVvx","colab_type":"code","colab":{}},"source":["# Run PCA on the actual data\n","top_comps, top_scores, top_eigenvals = pca(par_data, 2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6AdaoaspdRom","colab_type":"code","colab":{}},"source":["# Debugging info\n","print('top components: \\n{0}'.format(top_comps))\n","print('\\ntop scores (first three): \\n{0}'\n","       .format('\\n'.join(map(str, top_scores.take(3)))))\n","print('\\ntop eigenvalues: \\n{0}'.format(top_eigenvals))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1wtTuSTidtwi","colab_type":"text"},"source":["## 6 Test & Visualize Results\n","\n","Test the PCA on MNIST dataset.\n","\n","Plots the original data and its reconstructions using the top `k` principal components returned by our PCA function."]},{"cell_type":"markdown","metadata":{"id":"xqHhLfxqhUKK","colab_type":"text"},"source":["### 6.1 Test on MNIST Dataset"]},{"cell_type":"code","metadata":{"id":"-KXc_cuVhQCR","colab_type":"code","colab":{}},"source":["mnist = keras.datasets.mnist\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","# normalizing the data\n","x_train, x_test = x_train / 255.0, x_test /255.0"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nD01WnzChcE4","colab_type":"text"},"source":["### 6.2 Plot Results"]},{"cell_type":"code","metadata":{"id":"kYStvpQnd_FQ","colab_type":"code","colab":{}},"source":["# TODO: implement projection function"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Upy1igIqe4R8","colab_type":"code","colab":{}},"source":["# TODO Test & plot it"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"whMnGZySase_","colab_type":"text"},"source":["# PCA using Tensorflow\n","\n","References:\n","* https://medium.com/@mukesh.mithrakumar/principal-component-analysis-with-tensorflow-2-0-395aaf96bc"]},{"cell_type":"code","metadata":{"id":"qf9PsUcWdbPU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":694},"outputId":"764c670f-b639-4c78-aaed-8ac5d44108d5","executionInfo":{"status":"ok","timestamp":1587610299503,"user_tz":240,"elapsed":139974,"user":{"displayName":"Amy Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqLqJZ7tmS-RYlbHWq4vE0jqMMMMq8y5ez6PA-=s64","userId":"12521918565421128829"}}},"source":["# Install tensorflow_transform\n","import argparse\n","import os\n","import pprint\n","import tempfile\n","import urllib.request\n","import zipfile\n","\n","print(\"Installing dependencies for Colab environment\")\n","!pip install -Uq grpcio==1.26.0\n","\n","import tensorflow as tf\n","\n","print('Installing Apache Beam')\n","!pip install -Uq apache_beam==2.16.0\n","import apache_beam as beam\n","\n","print('Installing TensorFlow Transform')\n","!pip install -Uq tensorflow-transform==0.15.0"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Installing dependencies for Colab environment\n","\u001b[K     |████████████████████████████████| 2.4MB 2.8MB/s \n","\u001b[?25hInstalling Apache Beam\n","\u001b[K     |████████████████████████████████| 3.0MB 2.8MB/s \n","\u001b[K     |████████████████████████████████| 81kB 6.1MB/s \n","\u001b[K     |████████████████████████████████| 61kB 7.9MB/s \n","\u001b[K     |████████████████████████████████| 1.2MB 26.0MB/s \n","\u001b[K     |████████████████████████████████| 51kB 8.5MB/s \n","\u001b[K     |████████████████████████████████| 153kB 36.7MB/s \n","\u001b[K     |████████████████████████████████| 225kB 32.5MB/s \n","\u001b[K     |████████████████████████████████| 112kB 32.0MB/s \n","\u001b[?25h  Building wheel for oauth2client (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for httplib2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pydrive 1.3.1 has requirement oauth2client>=4.0.0, but you'll have oauth2client 3.0.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: multiprocess 0.70.9 has requirement dill>=0.3.1, but you'll have dill 0.3.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-api-python-client 1.7.12 has requirement httplib2<1dev,>=0.17.0, but you'll have httplib2 0.12.0 which is incompatible.\u001b[0m\n","Installing TensorFlow Transform\n","\u001b[K     |████████████████████████████████| 225kB 2.8MB/s \n","\u001b[K     |████████████████████████████████| 112kB 70.8MB/s \n","\u001b[K     |████████████████████████████████| 421.8MB 36kB/s \n","\u001b[K     |████████████████████████████████| 1.9MB 36.8MB/s \n","\u001b[K     |████████████████████████████████| 143kB 61.5MB/s \n","\u001b[K     |████████████████████████████████| 92kB 11.5MB/s \n","\u001b[K     |████████████████████████████████| 235kB 61.0MB/s \n","\u001b[K     |████████████████████████████████| 122kB 57.8MB/s \n","\u001b[K     |████████████████████████████████| 174kB 68.8MB/s \n","\u001b[K     |████████████████████████████████| 3.9MB 42.1MB/s \n","\u001b[K     |████████████████████████████████| 450kB 59.4MB/s \n","\u001b[K     |████████████████████████████████| 450kB 57.4MB/s \n","\u001b[?25h  Building wheel for tensorflow-transform (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for absl-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for google-apitools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for psutil (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for grpc-google-iam-v1 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: tensorflow-probability 0.10.0rc0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Bqw1cXVOauxN","colab_type":"code","colab":{}},"source":["import numpy as np\n","import tensorflow as tf\n","import tensorflow_transform as tft\n","from tensorflow import keras\n","from PIL import Image\n","import io\n","from tempfile import mkdtemp\n","import pickle as pkl\n","import tarfile\n","import scipy\n","import time"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_m2YHXmTaw6t","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":124},"outputId":"1bad16be-aefe-4a32-d139-8ec859b071c8","executionInfo":{"status":"ok","timestamp":1587610418572,"user_tz":240,"elapsed":27968,"user":{"displayName":"Amy Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqLqJZ7tmS-RYlbHWq4vE0jqMMMMq8y5ez6PA-=s64","userId":"12521918565421128829"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JyLf51K8a5iF","colab_type":"text"},"source":["Getting the preprocessed data"]},{"cell_type":"code","metadata":{"id":"XBFVSK7wazt9","colab_type":"code","colab":{}},"source":["filepath = \"/content/drive/My Drive/CMU 2020 S1 (Spring)/10-405: Machine Learning with Large Datasets/10605 Term Project/Data/train_img_array.pkl\"\n","fp = np.memmap(filepath, dtype = 'float32', mode = 'r', shape = (1803460,32,32))\n","fp = fp.reshape((1803460,-1))\n","data_tensor = tf.convert_to_tensor(fp, dtype = tf.float64)\n","\n","print('Finished loading data')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AlmaFlftC0Ar","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":199},"outputId":"214cd6ab-9422-46d3-c729-3783f5fa6eeb","executionInfo":{"status":"error","timestamp":1587614334581,"user_tz":240,"elapsed":506,"user":{"displayName":"Amy Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqLqJZ7tmS-RYlbHWq4vE0jqMMMMq8y5ez6PA-=s64","userId":"12521918565421128829"}}},"source":["train_data = fp[:1803000]\n","print('Data shape:', train_data.shape)\n","plt.imshow(train_data[100], cmap='Greys')"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-72f8050fa8ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1803000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data shape:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Greys'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'fp' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"-yiQeRc0bqsv","colab_type":"text"},"source":["Running PCA on the data"]},{"cell_type":"code","metadata":{"id":"BkscQZEtbFJv","colab_type":"code","colab":{}},"source":["# garbage collector\n","import gc\n","gc.collect()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jkwV-68VbOQX","colab_type":"code","colab":{}},"source":["# run pca & time it\n","start_time = time.time()\n","top_eigenvecs = tf.tft.pca(data_tensor, 128, dtype=int)\n","end_time  = time.time()\n","print('Orignial dimension: %d' % (data_tensor.shape[1]))\n","print('Output eigenvecs shape:', top_eigenvecs.shape)\n","print(\"handling %d data: --- {%s} seconds ---\" % (data_tensor.shape[0], time.time() - start_time))"],"execution_count":0,"outputs":[]}]}